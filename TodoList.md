- [ ] compress.cu 不再使用 read_unit_size 作为模板参数, 而是根据长度将数据类型分成
两类(uint8_t 和 uint16_t), 用这个长度类型作为模板参数. 这个优化很重要, 大部分数据集
的长度其实都只需要 uint8_t, 这块只要做了就能减少内存和显存的开销, 而且与序列长度
相关的很多数组, 比如 offset, read_off 等都可以减少数据大小. 
- [ ] compress.cu 在 PgMatcher 这块的实现需要迁移到 GPU 上, 具体的实现方法类似于
ReadMapper, 而且只要能迁移上去就能减少内存的开销, 同时提高压缩速度.
- [ ] compress.cu 目前在 CPU 上只有几个地方还没做多线程优化: 
  a. ref construct, 这块或许可以看成图, 然后用图的并行化搜索来加速;
  b. streams compression, 多个数据流的压缩现在还是串行的, 可以考虑每个流开一个线程. 
  c. encode process, 编码的过程还是串行的, 这块其实也可以多线程优化, 
  但需要提前创建每个stream所需的全部内存, 然后每个位置独立编码, 内存开销会比较大.
- [ ] 所有测试数据集的解压结果需要进行校验
- [ ] 解压函数需要进一步优化速度, 最简单是给每个stream的解压开一个线程,
 解码的过程也可以做多线程的优化, 也就是说不要每解压一条序列就输出到文件, 
 而是在内存额外开个数组然后并行解压再写入文件, 当然内存开销就比较大. 
 解压速度现在比PgRC还慢的原因可能是多个块每个块都有自己的stream需要解压, 
 而PgRC只需要处理整个文件的stream, 所以这里可以考虑多个块同时解压; 
 另外我感觉解压只用到了单线程, 但是fast-lzma2解压应该是多线程才对, 这里要查一下.
- [ ] benchmark 在 GPU 测试中需要加入 GPU_device_id_list 的命令行参数
- [ ] 之前多卡同时处理所有数据的压缩版本, 可以作为一个独立的模式加到 CURC 的代码中.
即提供一个压缩率最高但同时对显存需求更高的模式. 