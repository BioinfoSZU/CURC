- [ ] compress.cu 不再使用 read_unit_size 作为模板参数, 而是根据长度将数据类型分成
两类(uint8_t 和 uint16_t), 用这个长度类型作为模板参数. 这个优化很重要, 大部分数据集
的长度其实都只需要 uint8_t, 这块只要做了就能减少内存和显存的开销, 而且与序列长度
相关的很多数组, 比如 offset, read_off 等都可以减少数据大小. 
- [ ] compress.cu 在 PgMatcher 这块的实现需要迁移到 GPU 上, 具体的实现方法类似于
ReadMapper, 而且只要能迁移上去就能减少内存的开销, 同时提高压缩速度.
- [ ] compress.cu 目前在 CPU 上只有几个地方还没做多线程优化: 
  a. ref construct, 这块或许可以看成图, 然后用图的并行化搜索来加速;
  b. streams compression, 多个数据流的压缩现在还是串行的, 可以考虑每个流开一个线程. 
  c. encode process, 编码的过程还是串行的, 这块其实也可以多线程优化, 
  但需要提前创建每个stream所需的全部内存, 然后每个位置独立编码, 内存开销会比较大.
- [ ] 所有测试数据集的解压结果需要进行校验
- [ ] 解压函数需要进一步优化速度, 最简单是给每个stream的解压开一个线程,
 解码的过程也可以做多线程的优化, 也就是说不要每解压一条序列就输出到文件, 
 而是在内存额外开个数组然后并行解压再写入文件, 当然内存开销就比较大. 
 解压速度现在比PgRC还慢的原因可能是多个块每个块都有自己的stream需要解压, 
 而PgRC只需要处理整个文件的stream, 所以这里可以考虑多个块同时解压; 
 另外我感觉解压只用到了单线程, 但是fast-lzma2解压应该是多线程才对, 这里要查一下,
 另外好像 fast-lzma2 用多线程压缩所以解压会比较慢? 回头看一下它的主页说明.
- [ ] 之前多卡同时处理所有数据的压缩版本, 可以作为一个独立的模式加到 CURC 的代码中.
即提供一个压缩率最高但同时对显存需求更高的模式. 
- [ ] 目前的代码基本GPU非常快就能跑完, 时间都卡在CPU上, 这样的话感觉多卡的发挥就
很小了, 除非是同时压缩多个数据集, 但这里也存在一个改进的点就是在 preprocess 的时候
用多个线程同时读取多个块, 这样每个块的推进速度是一样的, 如果是多卡的话就可以
看到多个块同时在多张卡上运行, 但这样对速度能否有大的提升还不好说, 因为GPU这块的
耗时已经非常小, 所以如果要提升整体的速度应该还是得在CPU后端这里进一步优化一下.
而且如果系统的储存不是SSD而是HDD, 多个线程同时读取同一个文件可能会降低I/O的速度,
因为有一个寻道时间, SSD的话就还好, 但是SSD本身速度就蛮快的所以应该也不影响. 